[spark-conf]
    spark.memory.offHeap.enabled=true
    spark.executor.memoryOverhead=4096
    spark.memory.offHeap.size=4096
    spark.executor.memory=25g
    spark.executor.cores=4
    spark.executor.instances=30
    spark.default.parallelism=1000
    spark.sql.shuffle.partitions=1000
    spark.rpc.retry.wait=4s
    spark.locality.wait.process=10
    spark.locality.wait.node=5
    spark.locality.wait.rack=3
    spark.executor.extraJavaOptions=-XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+UseG1GC
    spark.sql.warehouse.dir=hdfs:///user/hive/warehouse
;     spark.sql.autoBroadcastJoinThreshold=1
;     spark.sql.join.preferSortMergeJoin=false

[hdfs]
    hdfs_qyxx_basic_path=basic/qyxx_basic
    hdfs_listed_person_path=input/listed_person_unique.csv
    hdfs_listed_name_path=basic/listed_name
    hdfs_conflict_path=property_conflict
    hdfs_basic_info_path=basic_info
    hdfs_black_path=blacklist