[spark-submit]
    spark_submit_path=/opt/spark-2.4.0/bin/spark-submit
    kerberos_user=
    kerberos_file=
[pyspark-env]
    spark_home=/opt/spark-2.4.0
[spark-submit-opt]
    master=yarn
    deploy-mode=client
    queue=root.project.bf-zg11
[spark-submit-conf]
    spark.pyspark.driver.python=/opt/anaconda3/bin/python
    spark.pyspark.python=/opt/anaconda3/bin/python
[spark-conf]
    spark.executor.memory=20g
    spark.executor.cores=4
    spark.executor.instances=40
    spark.default.parallelism=800
    spark.sql.shuffle.partitions=800
    spark.hadoop.dfs.replication=1
    spark.rpc.retry.wait=4s
    spark.locality.wait.process=10
    spark.locality.wait.node=5
    spark.locality.wait.rack=3
    spark.executor.extraJavaOptions=-XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+UseG1GC
    spark.sql.warehouse.dir=hdfs:///user/hive/warehouse
    spark.sql.autoBroadcastJoinThreshold=1
    spark.sql.join.preferSortMergeJoin=false
[hdfs]
    hdfs_root_path=/user/bf-zg11
    hdfs_input_path=input
    hdfs_path=basic
    hdfs_path_relation=relation
[mysql]
host=10.28.100.19
port=13306
user=root
passwd=cptbtptp
charset=utf8
dbname=listed_graph_input_test
[hive-dw]
    database = dw
[hive-biz]
    database = dw
[exec-mode]
    debug=1
