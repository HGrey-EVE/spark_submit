[spark-conf]
    spark.rdd.compress = true
    spark.executor.memory=16g
    spark.executor.cores=4
    spark.executor.instances=50
    spark.default.parallelism=600
    spark.sql.shuffle.partitions=600
    spark.rpc.retry.wait=4s
    spark.locality.wait.process=10
    spark.locality.wait.node=5
    spark.locality.wait.rack=3
    spark.executor.extraJavaOptions=-XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+UseG1GC
    spark.sql.warehouse.dir=hdfs:///user/hive/warehouse
    spark.sql.autoBroadcastJoinThreshold=1
    spark.network.timeout=300
    spark.sql.join.preferSortMergeJoin=false
    spark.hadoop.dfs.replication=1
[hdfs]
    hdfs_path=entity
    hdfs_basic_path=basic