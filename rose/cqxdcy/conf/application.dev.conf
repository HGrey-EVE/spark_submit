[spark-submit]
    spark_submit_path=/opt/spark-2.4.0/bin/spark-submit
    kerberos_user=
    kerberos_file=
[pyspark-env]
    spark_home=/opt/spark-2.4.0
[spark-submit-opt]
    master=yarn
    deploy-mode=client
    queue=project.cqxdcyfzyjy
[spark-submit-conf]
    spark.pyspark.driver.python=/opt/anaconda3/bin/python
    spark.pyspark.python=/opt/anaconda3/bin/python
[spark-conf]
    spark.executor.memory=20g
    spark.executor.cores=4
    spark.default.parallelism=1000
    spark.executor.instances=50
    spark.sql.shuffle.partitions=1000
    spark.rpc.retry.wait=4s
    spark.locality.wait.process=10
    spark.locality.wait.node=5
    spark.locality.wait.rack=3
    spark.executor.extraJavaOptions=-XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+UseG1GC
    spark.sql.warehouse.dir=hdfs:///user/hive/warehouse
    spark.sql.autoBroadcastJoinThreshold=1
    spark.sql.join.preferSortMergeJoin=false
[hdfs]
    hdfs_root_path=/user/cqxdcyfzyjy
    hdfs_path=cqxdcy
[elasticsearch]
    index_1=
    index_2=
    host=
    port=
    cluster=
[hbase]
    rowkey_1=
    rowkey_2=
    host=
    port=
[hive]
    database = dw

[sys]
log.path=
log.levels = sys,debug,info,warning,critical,error
log.maxHistory = 7
