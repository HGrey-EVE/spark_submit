[spark-submit]
    spark_submit_path=spark2-submit
    kerberos_user=
    kerberos_file=
[pyspark-env]
    spark_home=/opt/spark-2.4.2
[spark-submit-opt]
    master=yarn
    deploy-mode=client
[spark-submit-conf]
    spark.pyspark.driver.python=/opt/anaconda3/bin/python
    spark.pyspark.python=/opt/anaconda3/bin/python
[spark-submit-jar]
    jars=mysql-connector-java-5.1.47.jar
[hdfs]
    hdfs_root_path=/user/hakcredit/scwgj
    index_path=index
[external_data_path]
    all_company=index/depend_data/company_293.csv
    target_company=index/depend_data/new_company_list.csv
    all_offline_relations=index/depend_data/all_off_line_relations.csv
    offline_relations=index/depend_data/off_line_relations.csv
    negative_list=index/depend_data/negative_list.csv
    black_list=index/18/origin/black_list
    yxjnfjrjg_industry=index/depend_data/yxjnfjrjg_industry.csv
    pboc_cncc=asdfasdg

[elasticsearch]
    index_1=
    index_2=
    host=
    port=
    cluster=
[hbase]
    rowkey_1=
    rowkey_2=
    host=
    port=
[hive-dw]
    database = dw
[hive-biz]
    database = dw
    hive_cmd = hive -e
[mysql-source]
    ip=
    port=
    db_name=
    user=
    password=
[mysql-destination]
    ip=10.28.103.50
    port=3306
    db_name=waiguanju
    user=root
    password=bbd!@#
[exec-mode]
    debug=1