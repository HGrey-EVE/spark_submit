[spark-submit]
    spark_submit_path=/opt/spark-2.4.0/bin/spark-submit
    kerberos_user=
    kerberos_file=
[pyspark-env]
    spark_home=/opt/spark-2.4.0
[spark-submit-opt]
    master=yarn
    deploy-mode=client
    queue=root.project.commondataexport
[spark-submit-conf]
    spark.pyspark.driver.python=/opt/anaconda3/bin/python
    spark.pyspark.python=/opt/anaconda3/bin/python
[spark-conf]
    spark.executor.memory=16g
    spark.executor.cores=4
    spark.executor.instances=50
    spark.default.parallelism=1000
    spark.sql.shuffle.partitions=1000
    spark.rpc.retry.wait=4s
    spark.locality.wait.process=10
    spark.locality.wait.node=5
    spark.locality.wait.rack=3
    spark.executor.extraJavaOptions=-XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+UseG1GC
    spark.sql.warehouse.dir=hdfs:///user/hive/warehouse
    spark.sql.autoBroadcastJoinThreshold=1
    spark.sql.join.preferSortMergeJoin=false
[hdfs]
    hdfs_out_path=/user/hongjing/hongjing7/manage_recruit_dataflow
    hdfs_target_path=hdfs://bbdhbase1/user/hongjing/hongjing7/manage_recruit_dataflow
    hdfs_hfile_path=hdfs://bbdhbase1/user/hongjing/hongjing7/manage_recruit_hfile
[hbase]
    table_name=hongjing:manage_recruit_
    family_name=info
    hbase_columns=HBASE_ROW_KEY,info:company_name,info:er_json,info:rn_json
    meta_table_name=api_meta
    meta_row_key=manage_recruit_address_v1
    hfile_absolute_path=manage_recruit_address_v1
